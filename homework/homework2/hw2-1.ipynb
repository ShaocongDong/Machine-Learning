{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework2 Support Vector Machine\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the README session for:\n",
    "* Metric Number: `A0148008J`\n",
    "* Email: `e0012680@u.nus.edu`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Programming snippet for writing the output into a file (given in the assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def written_program_output (i, cost, kernel, gamma, degree):\n",
    "    ### The output of your program should be written in a file as follows.\n",
    "    #   for question 'i', write the output in 'problem-i.txt' file (e.g., 'problem-1a.txt')\n",
    "    current_pwd = os.path.join(os.getcwd(),'homework/homework2')\n",
    "    file_path = os.path.join(current_pwd, 'problem-'+i+'.txt')\n",
    "    fo = open(file_path, 'w')\n",
    "\n",
    "    # train your svm\n",
    "    # (n.b., svmTrain, svmPredict are not previously defined;\n",
    "    # you will have to supply code to implement them)\n",
    "    svmModel, totalSV  = svmTrain(dataTrain, labelTrain, cost, kernel, gamma, degree)\n",
    "\n",
    "    # test on the training data\n",
    "    trainAccuracy = svmPredict(dataTrain, labelTrain, svmModel)\n",
    "\n",
    "    # test on your test data\n",
    "    testAccuracy = svmPredict(dataTest, labelTest, svmModel)\n",
    "\n",
    "    # report your results in the file\n",
    "    fo.write(\"Kernel: \"+ str(kernel)+\"\\n\")\n",
    "    fo.write(\"Cost: \"+ str(cost)+ \"\\n\")\n",
    "    fo.write(\"Number of Support Vectors: \"+ str(totalSV)+\"\\n\")\n",
    "    fo.write(\"Train Accuracy: \"+ str(trainAccuracy)+\"\\n\")\n",
    "    fo.write(\"Test Accuracy: \" + str(testAccuracy)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 1 - US Postal Service Zip Code dataset\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up details\n",
    "current_pwd = os.path.join(os.getcwd(),'homework/homework2')\n",
    "\n",
    "train_data_path = os.path.join(current_pwd, 'hw2-1-train.txt')\n",
    "test_data_path = os.path.join(current_pwd, 'hw2-1-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load DataSet\n",
    "setTrain = np.loadtxt(train_data_path)\n",
    "setTest = np.loadtxt(test_data_path)\n",
    "# split the data sets\n",
    "labelTrain, dataTrain = setTrain[:,0], setTrain[:,1:3]\n",
    "labelTest, dataTest = setTest[:,0], setTest[:,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Self-Defined Functions\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svmTrain(dataTrain, labelTrain, cost, kernel, gamma, degree):\n",
    "    model = SVC(C=cost, kernel=kernel, gamma=gamma, degree=degree)\n",
    "    model.fit(dataTrain, labelTrain)\n",
    "    return model, model.support_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svmPredict(data, label, svmModel):\n",
    "    predict = svmModel.predict(data)\n",
    "    N = predict.shape[0]\n",
    "    return 1 - np.sum(predict!=label)/(N*1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testAccuracy(dataTrain, labelTrain, dataTest, labelTest, cost, kernel, gamma, degree):\n",
    "    model, totalSV = svmTrain(dataTrain, labelTrain, cost, kernel, gamma, degree)\n",
    "    return svmPredict(dataTest, labelTest, model), model, totalSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printToVariousSubset(dataTrain, labelTrain, dataTest, labelTest, cost, kernel, gamma, degree):\n",
    "    # {50, 100, 200, 800} of the subset of training data set\n",
    "    # Linear kernel for model fitting\n",
    "    for size in [50, 100, 200, 800]:\n",
    "        dataSubsetTrain = dataTrain[0:size,:]\n",
    "        labelSubsetTrain = labelTrain[0:size]\n",
    "        print(\"The accuracy using the first \"+ str(size)+\" of the training set is: \" + str(\n",
    "            testAccuracy(dataSubsetTrain, labelSubsetTrain, dataTest, labelTest, cost, kernel, gamma, degree)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printToVariousCostDegree(dataTrain, labelTrain, dataTest, labelTest, gamma):\n",
    "    # Degree Q is 2 or 5\n",
    "    # Cost has the following values: {0.0001, 0.001, 0.01, 1}\n",
    "    # Polynomial kernel for model fitting\n",
    "    kernel = 'poly'\n",
    "    for cost in [0.0001, 0.001, 0.01, 1]:\n",
    "        for degree in [2, 5]:\n",
    "            out_err, model, totalSV = testAccuracy(dataTrain, labelTrain, dataTest, labelTest, cost, \n",
    "                                           kernel, gamma, degree)\n",
    "            in_err = svmPredict(dataTrain, labelTrain, model)\n",
    "            print(\"Cost: \"+ str(cost)+\"  Degree: \"+ str(degree)\n",
    "                  +\"  in_error: \"+str(1-in_err)+\"  out_error: \"+ str(1-out_err)\n",
    "                  +\"  total SV: \"+str(totalSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printToVariousCostRBF(dataTrain, labelTrain, dataTest, labelTest, gamma, degree):\n",
    "    # Cost has the following values: C ∈ {0.01, 1, 10^2, 10^4, 10^6}\n",
    "    # RBF kernel for model fitting\n",
    "    # The rest parameter chosen to be the default values\n",
    "    kernel = 'rbf'\n",
    "    for cost in [0.01, 1, 100, 10000, 1000000]:\n",
    "        out_err, model, totalSV = testAccuracy(dataTrain, labelTrain, dataTest, labelTest, cost, \n",
    "                                           kernel, gamma, degree)\n",
    "        in_err = svmPredict(dataTrain, labelTrain, model)\n",
    "        print(\"Cost: \"+ str(cost) +\"  in_error: \"\n",
    "              + str(1-in_err)+\"  out_error: \"+ str(1-out_err)\n",
    "              +\"  total SV: \"+ str(totalSV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train using whole training data set and write the result to file\n",
    "written_program_output('1a', 1, 'linear', 'auto', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy using the first 50 of the training set is: 0.971698113208\nThe accuracy using the first 100 of the training set is: 0.978773584906\nThe accuracy using the first 200 of the training set is: 0.981132075472\nThe accuracy using the first 800 of the training set is: 0.978773584906\n"
     ]
    }
   ],
   "source": [
    "printToVariousSubset(dataTrain, labelTrain, dataTest, labelTest, 1, 'linear', 'auto', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.0001  Degree: 2  in_error: 0.0224215246637  out_error: 0.0306603773585  total SV: 510\nCost: 0.0001  Degree: 5  in_error: 0.00640614990391  out_error: 0.0188679245283  total SV: 42\nCost: 0.001  Degree: 2  in_error: 0.0070467648943  out_error: 0.0188679245283  total SV: 152\nCost: 0.001  Degree: 5  in_error: 0.00512491992313  out_error: 0.0165094339623  total SV: 28\nCost: 0.01  Degree: 2  in_error: 0.00448430493274  out_error: 0.0188679245283  total SV: 54\nCost: 0.01  Degree: 5  in_error: 0.00448430493274  out_error: 0.0165094339623  total SV: 28\nCost: 1  Degree: 2  in_error: 0.00448430493274  out_error: 0.0188679245283  total SV: 25\nCost: 1  Degree: 5  in_error: 0.00448430493274  out_error: 0.0165094339623  total SV: 26\n"
     ]
    }
   ],
   "source": [
    "printToVariousCostDegree(dataTrain, labelTrain, dataTest, labelTest, 'auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Statement_**\n",
    "1. When C = 0.0001, Ein is higher at Q = 5.\n",
    "2. When C = 0.001, the number of support vectors is lower at Q = 5.\n",
    "3. When C = 0.01, Ein is higher at Q = 5.\n",
    "4. When C = 1, Eout is lower at Q = 5.\n",
    "5. None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Answer_**\n",
    "1. False, Ein is lower at Q=5 when C=0.0001\n",
    "2. True, when C=0.001, number of support vector is 152 for Q=2 which is higher than 28 for Q=5\n",
    "3. False, Ein is the same for both, which is 0.00448430493274\n",
    "4. True, Eout is about 0.002 lower for Q=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 0.01  in_error: 0.00384368994234  out_error: 0.0212264150943  total SV: 347\nCost: 1  in_error: 0.00448430493274  out_error: 0.0212264150943  total SV: 31\nCost: 100  in_error: 0.00320307495195  out_error: 0.0188679245283  total SV: 20\nCost: 10000  in_error: 0.00256245996156  out_error: 0.0188679245283  total SV: 17\nCost: 1000000  in_error: 0.00128122998078  out_error: 0.0212264150943  total SV: 18\n"
     ]
    }
   ],
   "source": [
    "printToVariousCostRBF(dataTrain, labelTrain, dataTest, labelTest, 'auto', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question_**  \n",
    "  \n",
    "Which value of C ∈ {0.01, 1, 100, 104, 106} results in the lowest Ein? The lowest Eout?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Anwser_**\n",
    "1. For Ein, when C=10^6, it attends the lowest value, which is about 0.00013\n",
    "2. For Eout, when C=100 and C=10^4, it attends the lowest value, which is about 0.0189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Statement of Individual Work\n",
    "\n",
    "Please initial (between the square brackets) one of the following statements.\n",
    "\n",
    "[Dong Shaocong] I, <*A0148008J*>, certify that I have followed the CS 3244 Machine Learning class guidelines for homework assignments.  In particular, I expressly vow that I have followed the Facebook rule in discussing with others in doing the assignment and did not take notes (digital or printed) from the discussions.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
